{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gzip\n",
    "import sentencepiece as spm\n",
    "from collections import namedtuple\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, voc_size, in_channels, out_channels, kernel_size=3, stride=1):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.embeds = torch.nn.Embedding(voc_size, in_channels) \n",
    "\n",
    "        self.conv = torch.nn.Conv1d(in_channels, out_channels, kernel_size, stride)\n",
    "        self.fonc = torch.nn.ReLU()\n",
    "        self.linear = torch.nn.Linear(out_channels, 2)\n",
    "\n",
    "\n",
    "    def forward(self,seq):\n",
    "        x = self.embeds(seq)\n",
    "        x = x.permute((0,2,1))\n",
    "\n",
    "        x = self.fonc(self.conv(x))\n",
    "\n",
    "        x = torch.max(x, dim=2)[0].squeeze()\n",
    "\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch = namedtuple(\"Batch\", [\"text\", \"labels\"])\n",
    "\n",
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, text: torch.LongTensor, sizes: torch.LongTensor, labels: torch.LongTensor):\n",
    "        self.text = text\n",
    "        self.sizes = sizes\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index: int):\n",
    "        return self.text[self.sizes[index]:self.sizes[index+1]], self.labels[index].item()\n",
    "\n",
    "    @staticmethod\n",
    "    def collate(batch):\n",
    "        data = [item[0] for item in batch]\n",
    "        labels = [item[1] for item in batch]\n",
    "        return Batch(torch.nn.utils.rnn.pad_sequence(data, batch_first=True), torch.LongTensor(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('train-1000.pth') as fp:\n",
    "    train_ds = torch.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = DataLoader(train_ds, batch_size=100, collate_fn=TextDataset.collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN(1000,50,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(cnn.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,   200] loss: 0.000011\n",
      "[2,   400] loss: 0.000009\n",
      "[2,   600] loss: 0.000009\n",
      "[2,   800] loss: 0.000007\n",
      "[2,  1000] loss: 0.000007\n",
      "[2,  1200] loss: 0.000005\n",
      "[2,  1400] loss: 0.000005\n",
      "[2,  1600] loss: 0.000005\n",
      "[2,  1800] loss: 0.000004\n",
      "[2,  2000] loss: 0.000004\n",
      "[2,  2200] loss: 0.000008\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-cbcffaa6b022>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \"\"\"\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     91\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     92\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "running_loss = 0.0\n",
    "for i, (inputs, labels) in enumerate(train):\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs = cnn(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    running_loss += loss.item()\n",
    "    if i % 200 == 199:    # print every 2000 mini-batches\n",
    "        print('[%d, %5d] loss: %f' %\n",
    "              (1 + 1, i + 1, running_loss / 2000))\n",
    "        running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f2fc0267e90>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = next(iter(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56, 453,   8,  ...,   0,   0,   0],\n",
       "        [ 27,  70,   3,  ...,   0,   0,   0],\n",
       "        [  4, 406,  91,  ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [657,   8,   4,  ...,   0,   0,   0],\n",
       "        [863, 166,  14,  ...,   0,   0,   0],\n",
       "        [ 56, 287, 186,  ...,   0,   0,   0]])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeds = torch.nn.Embedding(1000, 50) \n",
    "t[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = t[0]\n",
    "embatch = embeds(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = torch.tensor([[4, 161], [20, 95]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex\n",
    "emex = embeds(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.5194e-02, -3.0971e-02, -2.5020e-02,  7.2886e-02, -6.4929e-01,\n",
       "           2.4296e-01, -9.8907e-01, -4.4139e-01,  2.1070e+00,  1.4871e+00,\n",
       "          -3.5173e-01,  1.2579e+00, -8.9647e-01,  3.8556e-01, -6.8871e-01,\n",
       "           1.8117e+00,  5.5743e-01,  1.3918e+00, -1.6131e-01,  1.3127e-01,\n",
       "          -4.2685e-01, -4.8727e-01,  1.3638e+00,  2.5317e+00, -5.1366e-01,\n",
       "           1.6517e+00, -1.0289e+00,  1.1382e+00,  4.8713e-01,  3.4250e-01,\n",
       "          -5.8573e-01,  1.8584e+00, -1.2124e+00, -4.2926e-01,  2.9952e-01,\n",
       "           7.5592e-01,  1.5582e-01,  3.7930e-02, -7.5514e-01, -6.1178e-01,\n",
       "           1.1400e+00,  1.4572e+00,  1.6356e+00, -1.0104e-01, -8.2862e-01,\n",
       "           1.6281e+00,  5.4878e-01,  7.8644e-02,  1.7108e-01,  1.0995e+00],\n",
       "         [ 7.7085e-01,  4.8239e-01,  1.7930e-01, -8.0880e-02,  1.3383e+00,\n",
       "           6.9776e-01,  1.2570e+00,  9.3019e-01, -4.9104e-01,  1.2738e-01,\n",
       "           2.2883e-01, -2.5553e-01, -1.2491e+00,  5.6594e-01, -2.5229e-01,\n",
       "           7.3076e-01, -3.1729e-01, -2.4146e+00, -5.2813e-01, -1.0966e+00,\n",
       "          -3.9395e-01, -8.5639e-01, -1.2011e+00, -1.0603e-01,  2.2496e+00,\n",
       "          -1.3000e-01, -8.2594e-01, -1.8955e+00, -5.3300e-01, -3.1336e+00,\n",
       "           8.9331e-01, -9.8308e-01,  8.0049e-01, -1.4190e+00, -9.4628e-01,\n",
       "           1.2245e-01, -5.6305e-01, -2.8872e-01,  1.0847e+00,  3.0769e-01,\n",
       "           4.9379e-01,  2.3769e+00,  3.3575e-01, -1.0325e+00, -9.3254e-01,\n",
       "          -3.0619e-01, -1.3609e+00,  1.8701e-01, -4.8890e-01, -1.7473e+00]],\n",
       "\n",
       "        [[-6.8781e-01, -2.0466e+00, -2.0414e+00,  1.6638e+00, -5.3398e-01,\n",
       "          -1.0408e+00,  7.8947e-01,  1.5093e-01,  2.9906e-01,  1.3467e+00,\n",
       "          -1.4304e+00,  2.3598e+00, -3.7714e-01,  2.0481e+00, -3.6515e-01,\n",
       "          -8.8016e-02, -1.5343e-01,  7.2207e-01,  1.9149e-01, -8.3100e-01,\n",
       "           1.0781e+00,  8.5838e-02, -1.3257e+00,  1.7755e+00, -2.0307e-01,\n",
       "           1.9959e+00, -5.9795e-01,  5.0494e-01,  5.8561e-01, -5.0415e-01,\n",
       "           1.1819e+00, -1.4157e+00,  2.3390e-01,  2.8981e-01,  2.8070e-01,\n",
       "          -1.0287e+00, -6.3323e-01,  9.6500e-01,  9.2731e-01,  3.5951e-01,\n",
       "          -9.8074e-01,  1.1034e+00,  1.6172e+00, -2.8773e-02,  1.4704e+00,\n",
       "          -1.2561e+00,  1.0828e+00,  3.2104e-01,  1.5874e+00,  1.4364e+00],\n",
       "         [-5.2698e-01,  1.1106e-01, -7.8718e-01, -7.5758e-05, -4.1687e-01,\n",
       "          -2.2648e+00,  1.1635e+00, -3.7252e-01,  8.3546e-01, -8.0571e-01,\n",
       "          -4.3802e-01,  1.4237e+00,  6.9968e-01,  6.7665e-01, -2.6214e-01,\n",
       "           8.3896e-01, -5.2452e-01, -2.9990e-01, -3.9541e-01,  1.0750e+00,\n",
       "          -1.8500e-01,  5.2968e-01, -8.2126e-01,  1.5144e+00,  1.8135e-01,\n",
       "           7.6483e-02,  4.7775e-01,  1.0829e+00,  7.7718e-01, -1.8852e-01,\n",
       "           6.8685e-01,  3.0350e-01, -1.4838e+00,  7.7367e-01, -1.2864e+00,\n",
       "           2.9342e-01, -1.3833e+00,  7.5049e-01, -2.0582e-01, -1.3870e+00,\n",
       "          -9.2151e-01,  1.9551e+00, -6.2685e-01,  5.2617e-02, -1.2233e-03,\n",
       "           1.3331e+00, -1.6624e+00, -8.5316e-01, -8.6142e-01,  1.0993e+00]]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0552,  0.7709],\n",
       "        [-0.0310,  0.4824],\n",
       "        [-0.0250,  0.1793],\n",
       "        [ 0.0729, -0.0809],\n",
       "        [-0.6493,  1.3383],\n",
       "        [ 0.2430,  0.6978],\n",
       "        [-0.9891,  1.2570],\n",
       "        [-0.4414,  0.9302],\n",
       "        [ 2.1070, -0.4910],\n",
       "        [ 1.4871,  0.1274],\n",
       "        [-0.3517,  0.2288],\n",
       "        [ 1.2579, -0.2555],\n",
       "        [-0.8965, -1.2491],\n",
       "        [ 0.3856,  0.5659],\n",
       "        [-0.6887, -0.2523],\n",
       "        [ 1.8117,  0.7308],\n",
       "        [ 0.5574, -0.3173],\n",
       "        [ 1.3918, -2.4146],\n",
       "        [-0.1613, -0.5281],\n",
       "        [ 0.1313, -1.0966],\n",
       "        [-0.4268, -0.3939],\n",
       "        [-0.4873, -0.8564],\n",
       "        [ 1.3638, -1.2011],\n",
       "        [ 2.5317, -0.1060],\n",
       "        [-0.5137,  2.2496],\n",
       "        [ 1.6517, -0.1300],\n",
       "        [-1.0289, -0.8259],\n",
       "        [ 1.1382, -1.8955],\n",
       "        [ 0.4871, -0.5330],\n",
       "        [ 0.3425, -3.1336],\n",
       "        [-0.5857,  0.8933],\n",
       "        [ 1.8584, -0.9831],\n",
       "        [-1.2124,  0.8005],\n",
       "        [-0.4293, -1.4190],\n",
       "        [ 0.2995, -0.9463],\n",
       "        [ 0.7559,  0.1225],\n",
       "        [ 0.1558, -0.5630],\n",
       "        [ 0.0379, -0.2887],\n",
       "        [-0.7551,  1.0847],\n",
       "        [-0.6118,  0.3077],\n",
       "        [ 1.1400,  0.4938],\n",
       "        [ 1.4572,  2.3769],\n",
       "        [ 1.6356,  0.3357],\n",
       "        [-0.1010, -1.0325],\n",
       "        [-0.8286, -0.9325],\n",
       "        [ 1.6281, -0.3062],\n",
       "        [ 0.5488, -1.3609],\n",
       "        [ 0.0786,  0.1870],\n",
       "        [ 0.1711, -0.4889],\n",
       "        [ 1.0995, -1.7473]], grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emex.permute([0,2,1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 50])"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(text=tensor([[ 17, 456,  63,  ...,   0,   0,   0],\n",
       "        [  4,  26, 395,  ...,   0,   0,   0],\n",
       "        [174,  28, 289,  ...,   0,   0,   0],\n",
       "        ...,\n",
       "        [ 27,  25, 829,  ...,   0,   0,   0],\n",
       "        [ 21,  36, 481,  ...,   0,   0,   0],\n",
       "        [  4, 900,  43,  ...,   0,   0,   0]]), labels=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0]))"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = spm.SentencePieceProcessor()\n",
    "tokenizer.Load(f\"wp1000.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁I', '▁am', '▁you', '▁are']\n",
      "[4, 161, 20, 95]\n",
      "I love\n",
      "Thriving Ivory s song quot;Twilight quot; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; gt; the other Twilight\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode_as_pieces(\"I am you are\"))\n",
    "print(tokenizer.encode_as_ids(\"I am you are\"))\n",
    "print(tokenizer.decode_ids([4, 115]))\n",
    "\n",
    "exemple = train_ds[1447652][0].tolist()\n",
    "print(tokenizer.decode_ids(exemple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([620, 125,  91,   9,   4,  91,  74,  13,  10, 562, 101,  44, 120,  53,\n",
       "         106, 231, 101,  44, 138,  16,  44, 138,  16,  44, 138,  16,  44, 138,\n",
       "          16,  44, 138,  16,  44, 138,  16,  44, 138,  16,  44, 138,  16,  44,\n",
       "         138,  16,  44, 138,  16,  44, 138,  16,  44, 138,  16,  44, 138,  16,\n",
       "          44, 138,  16,  44, 138,  16,  44, 138,  16,  44, 138,  16,  44, 138,\n",
       "          16,  44, 138,  16,  44, 138,  16,  44, 138,  16,  44, 138,  16,  44,\n",
       "         138,  16,  44, 138,  16,  44, 138,  16,  44, 138,  16,  44, 138,  16,\n",
       "          44, 138,  16,  44, 138,  16,  44, 138,  16,  44, 138,  16,  44, 138,\n",
       "          16,  44, 138,  16,  44, 138,  16,  44, 138,  16,  44, 138,  16,  44,\n",
       "         138,  16,  44, 138,  16,  44, 138,  16,  44, 138,  16,  44, 138,  16,\n",
       "          44, 138,  16,  44, 138,  16,  44,   7, 571,  88,  53, 106, 231]), 1)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[1447652]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600000"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [len(x[0]) for x in train_ds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1447652"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.index(153)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ⁇ \n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode_ids([0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-bcff227c36ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m153\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-3-f8579678433c>\u001b[0m in \u001b[0;36mcollate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcollate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mBatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_first\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "#TextDataset.collate(153)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self(CNN, self).__init__()\n",
    "        \n",
    "        self.conv1(,)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN\n",
    "\n",
    "Conv 1D\n",
    "max pool\n",
    "\n",
    "Conv 1D\n",
    "\n",
    "(taille de fenetre diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
